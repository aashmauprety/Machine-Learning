{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL_VANET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4XiBgJdcVxtR/syWbgp+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashmauprety/Machine-Learning/blob/master/FL_VANET_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIlLvvstLdwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, average_precision_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSS6GK2aORn5",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "dcab27d9-8517-4df2-8eb4-4b523339fe7d"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68b73e5d-e770-461d-a883-35bdaf724524\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68b73e5d-e770-461d-a883-35bdaf724524\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dR3sPiTOWP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "173d4972-8113-448d-b168-24cb684b1532"
      },
      "source": [
        "!unrar x \"/content/data.rar\" "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/data.rar\n",
            "\n",
            "Extracting  Attack4.csv                                                  \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  Attack8.csv                                                  \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  Attack16.csv                                                 \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  allattack.csv                                                \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  Attack1.csv                                                  \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  Attack2.csv                                                  \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIld4IvdOlkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDOnExG-OoQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"Finaldata1.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKGU1NPQOupS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = dataset.iloc[:,:6].values\n",
        "y = dataset.iloc[:,6:7].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C7CrLJNOykq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caSy_RU6O76x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhhh9zLFPLUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=109)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_BdN3p2PSCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc6dafd2-432d-4d9d-f8ab-733b9ee97762"
      },
      "source": [
        "print(y[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM08oxSlPWM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad314967-ebf9-4ef9-f753-2858d639eb39"
      },
      "source": [
        "print(len(y))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PomfF69APd63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_clients(X, y, num_clients=10, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as \n",
        "                data shards - tuple of images and label lists.\n",
        "        args: \n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1 \n",
        "            \n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    data = list(zip(X, y))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Q9iWM0wJiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create clients\n",
        "clients = create_clients(X_train, y_train, num_clients=10, initial='client')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMinndskwKaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_data(data_shard, bs=32):\n",
        "    '''Takes in a clients data shard and create a tfds object of it\n",
        "    args:\n",
        "        shard: a data, label constituting a client's data shard\n",
        "        bs:batch size\n",
        "    return:\n",
        "        tfds object'''\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(bs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty64pf9axp2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "    # print(\"aashma\")\n",
        "#process and batch the test set  \n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HfITn7Lx2JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba6e35ae-2565-4e0e-d434-b3a21b26a115"
      },
      "source": [
        "print(clients_batched['client_1'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 6), (None, 6)), types: (tf.float64, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0YRpOUyEAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleMLP:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = Sequential()\n",
        "        model.add(Dropout(0.2, input_shape=(6,)))\n",
        "        model.add(Dense(200, input_shape=(shape,)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(200))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"sigmoid\"))\n",
        "        return model"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmuNkGpmyL6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.01 \n",
        "comms_round = 20\n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=lr, \n",
        "                decay=lr / 10,\n",
        "                momentum = 0.9\n",
        "               )            "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es0ENS6SyWbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "    return local_count/global_count"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGnFRjYXzBvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftO4wShPzatA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "        \n",
        "    return avg_grad"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVqzp1TBzdLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('Communication Round: {} | acc: {:.3%} | loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbLC1NE1zpXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "ae00cb06-99cf-4415-df0d-2dfd2b7f379e"
      },
      "source": [
        "#initialize global model\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(6, 6)\n",
        "\n",
        "global_acc_list = []\n",
        "global_loss_list = []\n",
        "global_precision_list = []\n",
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "    \n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "    \n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "    \n",
        "    #loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = SimpleMLP()\n",
        "        local_model = smlp_local.build(6, 6)\n",
        "        local_model.compile(loss=loss, \n",
        "                      optimizer=optimizer, \n",
        "                      metrics=metrics)\n",
        "        \n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "        \n",
        "        # print(len(clients_batched[client]))\n",
        "        #fit local model with client's data\n",
        "        # checkpoint_filepath = '/content/sample_data/model.h5'\n",
        "        # model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        # filepath=checkpoint_filepath,\n",
        "        # save_weights_only=True,\n",
        "        # monitor='val_acc',\n",
        "        # mode='max',\n",
        "        # save_best_only=True)\n",
        "\n",
        "\n",
        "        local_model.fit(clients_batched[client], epochs=2, verbose=0)\n",
        "        \n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "        \n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "        \n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "    \n",
        "    #update global model \n",
        "    global_model.set_weights(average_weights)\n",
        "    model_json = global_model.to_json()\n",
        "    with open(\"global_model.json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    print(\"Saved model to disk\")\n",
        "    global_model.save_weights(\"model.h5\")\n",
        "\n",
        "   \n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
        "        global_acc_list.append(global_acc)\n",
        "        global_loss_list.append(global_loss)\n",
        "        y_pred = global_model.predict(X_test)\n",
        "        global_precision = precision_score(tf.argmax(y_pred, axis=1), tf.argmax(Y_test, axis=1), average='weighted')\n",
        "        global_precision_list.append(global_precision)\n",
        "        "
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "Communication Round: 0 | acc: 87.364% | loss: 1.2347651720046997\n",
            "Saved model to disk\n",
            "Communication Round: 1 | acc: 87.465% | loss: 1.237684965133667\n",
            "Saved model to disk\n",
            "Communication Round: 2 | acc: 87.459% | loss: 1.2395461797714233\n",
            "Saved model to disk\n",
            "Communication Round: 3 | acc: 87.465% | loss: 1.2405999898910522\n",
            "Saved model to disk\n",
            "Communication Round: 4 | acc: 87.484% | loss: 1.2414370775222778\n",
            "Saved model to disk\n",
            "Communication Round: 5 | acc: 87.484% | loss: 1.2419508695602417\n",
            "Saved model to disk\n",
            "Communication Round: 6 | acc: 87.484% | loss: 1.2424472570419312\n",
            "Saved model to disk\n",
            "Communication Round: 7 | acc: 87.478% | loss: 1.242926001548767\n",
            "Saved model to disk\n",
            "Communication Round: 8 | acc: 87.478% | loss: 1.2432820796966553\n",
            "Saved model to disk\n",
            "Communication Round: 9 | acc: 87.484% | loss: 1.2436187267303467\n",
            "Saved model to disk\n",
            "Communication Round: 10 | acc: 87.484% | loss: 1.2438689470291138\n",
            "Saved model to disk\n",
            "Communication Round: 11 | acc: 87.484% | loss: 1.2441434860229492\n",
            "Saved model to disk\n",
            "Communication Round: 12 | acc: 87.484% | loss: 1.2443549633026123\n",
            "Saved model to disk\n",
            "Communication Round: 13 | acc: 87.484% | loss: 1.2445085048675537\n",
            "Saved model to disk\n",
            "Communication Round: 14 | acc: 87.490% | loss: 1.2447407245635986\n",
            "Saved model to disk\n",
            "Communication Round: 15 | acc: 87.490% | loss: 1.2449145317077637\n",
            "Saved model to disk\n",
            "Communication Round: 16 | acc: 87.490% | loss: 1.245074987411499\n",
            "Saved model to disk\n",
            "Communication Round: 17 | acc: 87.490% | loss: 1.245233416557312\n",
            "Saved model to disk\n",
            "Communication Round: 18 | acc: 87.490% | loss: 1.245384931564331\n",
            "Saved model to disk\n",
            "Communication Round: 19 | acc: 87.490% | loss: 1.2455358505249023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlcC6kZlqJsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "99760ec2-ea14-444f-eeba-02ff5bca497e"
      },
      "source": [
        "y_pred = global_model.predict(X_test)\n",
        "# Model Precision: what percentage of positives are labeled as such?\n",
        "print(\"Precision:\",precision_score(tf.argmax(y_pred, axis=1), tf.argmax(y_test, axis=1), average='weighted'))\n",
        "# print(\"MAP\", average_precision_score(tf.argmax(y_pred, axis=1), tf.argmax(Y_test, axis=1), average='macro', pos_label=1, sample_weight=None))\n",
        "global_prec= np.array(global_precision_list)\n",
        "global_acc = np.array(global_acc_list)\n",
        "print(global_prec)\n",
        "print(global_acc)\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9694170937798399\n",
            "[0.9678234  0.96871298 0.9690682  0.96924173 0.9692416  0.9692416\n",
            " 0.96928979 0.96935855 0.96941709 0.96941709]\n",
            "[0.87167469 0.87256144 0.87294147 0.87313149 0.87313149 0.87313149\n",
            " 0.87319483 0.87325817 0.87332151 0.87332151]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-LG6_OO7rma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "06605f28-75d0-42ef-92d3-f2ebd12c83f8"
      },
      "source": [
        "plt.plot(global_prec)\n",
        "plt.plot(global_acc)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feb102996a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ioCUhfJjQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # precision recall curve\n",
        "# precision = dict()\n",
        "# recall = dict()\n",
        "# for i in range(6):\n",
        "#     precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_pred[:, i])\n",
        "#     plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
        "#     print(recall[i])\n",
        "# plt.xlabel(\"recall\")\n",
        "# plt.ylabel(\"precision\")\n",
        "# plt.legend(loc=\"best\")\n",
        "# plt.title(\"precision vs. recall curve\")\n",
        "# plt.show()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7shLUPGzxAQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "2cfaa130-e628-4378-926a-4c4073226c56"
      },
      "source": [
        "attack1 = pd.read_csv(\"Attack1.csv\")\n",
        "X1 = attack1.iloc[:,:6].values\n",
        "y1 = attack1.iloc[:,6:7].values\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X1 = sc.fit_transform(X1)\n",
        "lb = LabelBinarizer()\n",
        "y1 = lb.fit_transform(y1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train1,X_test1,y_train1,y_test1 = train_test_split(X1,y1,test_size=0.1,random_state=109)\n",
        "y1_pred = global_model.predict(X_test1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "attack2 = pd.read_csv(\"Attack2.csv\")\n",
        "X2 = attack1.iloc[:,:6].values\n",
        "y2 = attack1.iloc[:,6:7].values\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X2 = sc.fit_transform(X2)\n",
        "lb = LabelBinarizer()\n",
        "y2 = lb.fit_transform(y2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train2,X_test2,y_train2,y_test2 = train_test_split(X2,y2,test_size=0.1,random_state=109)\n",
        "y2_pred = global_model.predict(X_test2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "attack4 = pd.read_csv(\"Attack4.csv\")\n",
        "X4 = attack1.iloc[:,:6].values\n",
        "y4 = attack1.iloc[:,6:7].values\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X4 = sc.fit_transform(X4)\n",
        "lb = LabelBinarizer()\n",
        "y4 = lb.fit_transform(y4)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train4,X_test4,y_train4,y_test4 = train_test_split(X4,y4,test_size=0.1,random_state=109)\n",
        "y4_pred = global_model.predict(X_test4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "attack8 = pd.read_csv(\"Attack8.csv\")\n",
        "X8 = attack1.iloc[:,:6].values\n",
        "y8 = attack1.iloc[:,6:7].values\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X8 = sc.fit_transform(X8)\n",
        "lb = LabelBinarizer()\n",
        "y8 = lb.fit_transform(y8)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train8,X_test8,y_train8,y_test8 = train_test_split(X8,y8,test_size=0.1,random_state=109)\n",
        "y8_pred = global_model.predict(X_test8)\n",
        "\n",
        "\n",
        "\n",
        "attack16 = pd.read_csv(\"Attack16.csv\")\n",
        "X16 = attack1.iloc[:,:6].values\n",
        "y16 = attack1.iloc[:,6:7].values\n",
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X16 = sc.fit_transform(X16)\n",
        "lb = LabelBinarizer()\n",
        "y16 = lb.fit_transform(y16)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train16,X_test16,y_train16,y_test16 = train_test_split(X16,y16,test_size=0.1,random_state=109)\n",
        "y16_pred = global_model.predict(X_test16)\n",
        "\n",
        "\n",
        "print(\"Precision for Attack 1:\",precision_score(tf.argmax(y1_pred, axis=1), tf.argmax(y_test1, axis=1), average='weighted'))\n",
        "print(\"Precision for Attack 2:\",precision_score(tf.argmax(y2_pred, axis=1), tf.argmax(y_test2, axis=1), average='weighted'))\n",
        "print(\"Precision for Attack 4:\",precision_score(tf.argmax(y4_pred, axis=1), tf.argmax(y_test4, axis=1), average='weighted'))\n",
        "print(\"Precision for Attack 8:\",precision_score(tf.argmax(y8_pred, axis=1), tf.argmax(y_test8, axis=1), average='weighted'))\n",
        "print(\"Precision for Attack 16:\",precision_score(tf.argmax(y16_pred, axis=1), tf.argmax(y_test16, axis=1), average='weighted'))\n",
        "\n",
        "# print(\"MAP\", average_precision_score(tf.argmax(y_pred, axis=1), tf.argmax(Y_test, axis=1), average='macro', pos_label=1, sample_weight=None))\n",
        "global_prec= np.array(global_precision_list)\n",
        "print(f\"Precision for each round: {global_prec}\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision for Attack 1: 0.7547661476180705\n",
            "Precision for Attack 2: 0.7547661476180705\n",
            "Precision for Attack 4: 0.7547661476180705\n",
            "Precision for Attack 8: 0.7547661476180705\n",
            "Precision for Attack 16: 0.7547661476180705\n",
            "Precision for each round: [0.9678234  0.96871298 0.9690682  0.96924173 0.9692416  0.9692416\n",
            " 0.96928979 0.96935855 0.96941709 0.96941709]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}